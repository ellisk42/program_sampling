\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{graves2014neural,DBLP:journals/corr/ReedF15}
\citation{lake2015human,DBLP:conf/icml/LiangJK10,menon2013machine}
\citation{solar2008program}
\citation{ermon2013embed}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}}
\newlabel{introduction}{{1}{1}{Introduction}{section.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Motivation and problem statement}{1}{subsection.1.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Learning string manipulation programs by example (top input/output pair). Our system receives data like that shown above and then sampled the programs shown below.\relax }}{1}{figure.caption.2}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{ambiguous}{{1}{1}{Learning string manipulation programs by example (top input/output pair). Our system receives data like that shown above and then sampled the programs shown below.\relax }{figure.caption.2}{}}
\citation{solar2008program}
\citation{solar2008program,jha2010oracle}
\citation{gomes2006near,ermon2013embed,AAAI148364,chakraborty2013scalable}
\citation{solar2008program,jha2010oracle}
\citation{gomes2006near}
\citation{gomes2006near,ermon2013embed,AAAI148364}
\citation{AAAI148364}
\citation{AAAI148364}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Program synthesis by constraint solving}{2}{subsection.1.2}}
\newlabel{brisk}{{1.2}{2}{Program synthesis by constraint solving}{subsection.1.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}Algorithmic contribution}{2}{subsection.1.3}}
\citation{ermon2013embed}
\citation{AAAI148364}
\citation{ermon2013embed}
\citation{gomes2006near,valiant1985np,AAAI148364,gomes2006model,chakraborty2013scalable}
\newlabel{booleanSketch}{{2a}{3}{Subfigure 2a}{subfigure.2.1}{}}
\newlabel{sub@booleanSketch}{{(a)}{a}{Subfigure 2a\relax }{subfigure.2.1}{}}
\newlabel{booleanSpace}{{2b}{3}{Subfigure 2b}{subfigure.2.2}{}}
\newlabel{sub@booleanSpace}{{(b)}{b}{Subfigure 2b\relax }{subfigure.2.2}{}}
\newlabel{booleanModel}{{2c}{3}{Subfigure 2c}{subfigure.2.3}{}}
\newlabel{sub@booleanModel}{{(c)}{c}{Subfigure 2c\relax }{subfigure.2.3}{}}
\newlabel{booleanSpecification}{{2d}{3}{Subfigure 2d}{subfigure.2.4}{}}
\newlabel{sub@booleanSpecification}{{(d)}{d}{Subfigure 2d\relax }{subfigure.2.4}{}}
\newlabel{booleanSolution}{{2e}{3}{Subfigure 2e}{subfigure.2.5}{}}
\newlabel{sub@booleanSolution}{{(e)}{e}{Subfigure 2e\relax }{subfigure.2.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Synthesizing a program via sketching and constraint solving. {\ttfamily  Typewriter font} refers to pieces of programs or sketches, while math font refers to pieces of a constraint satisfaction problem. The variable {\ttfamily  i} is the program input.\relax }}{3}{figure.caption.3}}
\newlabel{booleanExample}{{2}{3}{Synthesizing a program via sketching and constraint solving. {\ttfamily Typewriter font} refers to pieces of programs or sketches, while math font refers to pieces of a constraint satisfaction problem. The variable {\ttfamily i} is the program input.\relax }{figure.caption.3}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Sketch}}}{3}{subfigure.2.1}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Program space}}}{3}{subfigure.2.2}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {Constraints for SAT solver}}}{3}{subfigure.2.3}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(d)}{\ignorespaces {Specification}}}{3}{subfigure.2.4}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(e)}{\ignorespaces {A constraint solution; $|x| = 3$ bits}}}{3}{subfigure.2.5}}
\@writefile{toc}{\contentsline {section}{\numberline {2}The sampling algorithm}{3}{section.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Getting high-quality samples}{3}{subsection.2.1}}
\citation{ermon2013embed}
\citation{gomes2006near}
\citation{AAAI148364,ermon2014low,achlioptas2015stochastic}
\citation{gomes2006near,valiant1985np,AAAI148364,gomes2006model,chakraborty2013scalable}
\citation{ermon2013embed}
\newlabel{acceptanceBound}{{1}{4}{}{proposition.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces \textsc  {ProgramSample}{} twice distorts the posterior distribution $p(\cdot )$. First it introduces a parameter $d$ that bounds the tilt; we correct for this by accepting samples w.p. $A(x)$. Second it samples from $q(\cdot )$ by drawing instead from $r(\cdot )$, where $KL(q||r)$ can be made arbitrarily small by appropriately setting another parameter, $K$. The distribution of samples is $A(x)r(x)$.\relax }}{4}{figure.caption.4}}
\newlabel{cartoon}{{3}{4}{\theSystem {} twice distorts the posterior distribution $p(\cdot )$. First it introduces a parameter $d$ that bounds the tilt; we correct for this by accepting samples w.p. $A(x)$. Second it samples from $q(\cdot )$ by drawing instead from $r(\cdot )$, where $KL(q||r)$ can be made arbitrarily small by appropriately setting another parameter, $K$. The distribution of samples is $A(x)r(x)$.\relax }{figure.caption.4}{}}
\newlabel{propositionLowerBound}{{2}{4}{}{proposition.2}{}}
\citation{singh2013automated}
\citation{gomes2006model}
\citation{solar2008program}
\citation{crypto}
\citation{gulwani2011automating}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces \textsc  {ProgramSample}{}\relax }}{5}{algorithm.1}}
\newlabel{mainAlgorithm}{{1}{5}{\theSystem {}\relax }{algorithm.1}{}}
\newlabel{mainResult}{{3}{5}{}{proposition.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Experimental results}{5}{section.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Learning Text Edit Scripts}{5}{subsection.3.1}}
\citation{DBLP:conf/ecai/LinDETM14}
\citation{ermon2013embed}
\citation{solar2008program}
\citation{gulwani2011automating}
\citation{raychev2016learning,ellis2015unsupervised,singh2013automated}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces The sketch (program space) for learning text edit scripts\relax }}{6}{figure.caption.5}}
\newlabel{textGrammar}{{4}{6}{The sketch (program space) for learning text edit scripts\relax }{figure.caption.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Generalization when learning text edit operations by example. Results averaged across 19 problems. Solid: 100 samples from \textsc  {ProgramSample}{} . Dashed: enumerating 100 programs. Dotted: MDL learner. Test cases past 1 (respectively 2,3) examples are held out when trained on 1 (respectively 2,3) examples.\relax }}{6}{figure.caption.6}}
\newlabel{flashPerformance}{{5}{6}{Generalization when learning text edit operations by example. Results averaged across 19 problems. Solid: 100 samples from \theSystem {} . Dashed: enumerating 100 programs. Dotted: MDL learner. Test cases past 1 (respectively 2,3) examples are held out when trained on 1 (respectively 2,3) examples.\relax }{figure.caption.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Comparing the MDL learner (dashed black line) to program sampling when doing one-shot learning. We count a problem as ``solved'' if the correct joint prediction to the test cases is in the top $C$ most frequent samples.\relax }}{6}{figure.caption.6}}
\newlabel{mdl}{{6}{6}{Comparing the MDL learner (dashed black line) to program sampling when doing one-shot learning. We count a problem as ``solved'' if the correct joint prediction to the test cases is in the top $C$ most frequent samples.\relax }{figure.caption.6}{}}
\citation{DBLP:books/daglib/0070933}
\citation{schkufza2013stochastic}
\citation{DBLP:conf/icml/LiangJK10,menon2013machine}
\citation{DBLP:journals/corr/ReedF15,graves2014neural}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Average solver time to generate a sample measured in seconds. See Figure\nobreakspace  {}\ref  {listCurves} and \ref  {flashPerformance} for training set sizes. $n \approx 180,\tmspace  +\thickmuskip {.2777em}65$ for text edit, list manipulation domains, respectively. w/o tilt correction, sampling text edit \& count takes $ > 1$ hour.\relax }}{7}{figure.caption.7}}
\newlabel{listTimes}{{1}{7}{Average solver time to generate a sample measured in seconds. See Figure~\ref {listCurves} and \ref {flashPerformance} for training set sizes. $n \approx 180,\;65$ for text edit, list manipulation domains, respectively. w/o tilt correction, sampling text edit \& count takes $ > 1$ hour.\relax }{figure.caption.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Sampling frequency vs. ground truth probability on a counting task with $\Delta = 3$ and $\gamma = 4$.\relax }}{7}{figure.caption.7}}
\newlabel{marginal}{{7}{7}{Sampling frequency vs. ground truth probability on a counting task with $\Delta = 3$ and $\gamma = 4$.\relax }{figure.caption.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Learning list manipulation algorithms}{7}{subsection.3.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces The sketch (program space) for learning list manipulation routines; {\ttfamily  X} is program input\relax }}{7}{figure.caption.8}}
\newlabel{ListGrammar}{{8}{7}{The sketch (program space) for learning list manipulation routines; {\ttfamily X} is program input\relax }{figure.caption.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Learning to manipulate lists. Trained on lists of length $\leq 3$; tested on lists of length $\leq 14$.\relax }}{7}{figure.caption.8}}
\newlabel{listCurves}{{9}{7}{Learning to manipulate lists. Trained on lists of length $\leq 3$; tested on lists of length $\leq 14$.\relax }{figure.caption.8}{}}
\citation{raychev2016learning,ellis2015unsupervised,singh2013automated}
\citation{gomes2006near,gomes2006model}
\citation{ermon2014low,achlioptas2015stochastic}
\citation{solar2008program}
\citation{schkufza2013stochastic,DBLP:books/daglib/0070933}
\citation{ellis2015unsupervised,raychev2016learning}
\citation{gomes2006model}
\citation{liang11dcs}
\citation{lake2015human}
\citation{logical}
\bibstyle{unsrt}
\bibdata{main}
\bibcite{graves2014neural}{{1}{}{{}}{{}}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Discussion}{8}{section.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Related work}{8}{subsection.4.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Limitations of the approach}{8}{subsection.4.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Future work}{8}{subsection.4.3}}
\bibcite{DBLP:journals/corr/ReedF15}{{2}{}{{}}{{}}}
\bibcite{lake2015human}{{3}{}{{}}{{}}}
\bibcite{DBLP:conf/icml/LiangJK10}{{4}{}{{}}{{}}}
\bibcite{menon2013machine}{{5}{}{{}}{{}}}
\bibcite{solar2008program}{{6}{}{{}}{{}}}
\bibcite{ermon2013embed}{{7}{}{{}}{{}}}
\bibcite{jha2010oracle}{{8}{}{{}}{{}}}
\bibcite{gomes2006near}{{9}{}{{}}{{}}}
\bibcite{AAAI148364}{{10}{}{{}}{{}}}
\bibcite{chakraborty2013scalable}{{11}{}{{}}{{}}}
\bibcite{valiant1985np}{{12}{}{{}}{{}}}
\bibcite{gomes2006model}{{13}{}{{}}{{}}}
\bibcite{ermon2014low}{{14}{}{{}}{{}}}
\bibcite{achlioptas2015stochastic}{{15}{}{{}}{{}}}
\bibcite{singh2013automated}{{16}{}{{}}{{}}}
\bibcite{crypto}{{17}{}{{}}{{}}}
\bibcite{gulwani2011automating}{{18}{}{{}}{{}}}
\bibcite{DBLP:conf/ecai/LinDETM14}{{19}{}{{}}{{}}}
\bibcite{raychev2016learning}{{20}{}{{}}{{}}}
\bibcite{ellis2015unsupervised}{{21}{}{{}}{{}}}
\bibcite{DBLP:books/daglib/0070933}{{22}{}{{}}{{}}}
\bibcite{schkufza2013stochastic}{{23}{}{{}}{{}}}
\bibcite{liang11dcs}{{24}{}{{}}{{}}}
\bibcite{logical}{{25}{}{{}}{{}}}
\providecommand\NAT@force@numbers{}\NAT@force@numbers
